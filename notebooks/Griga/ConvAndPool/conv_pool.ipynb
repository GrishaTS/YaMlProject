{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Polling\n",
    "полезные ссылки:\n",
    "- https://youtu.be/vVaRhZXovbw\n",
    "- https://androidkt.com/explain-pooling-layers-max-pooling-average-pooling-global-average-pooling-and-global-max-pooling/\n",
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conv1D vs Conv2D vs Conv3D\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D (фильтр/ядро скользит в одном измерении)\n",
    "- Conv1D фиксирует только одну из двух корреляций (вертикальную или горизонтальную), что дает гораздо более ограниченную информацию.\n",
    "![-](data/conv1d_il.jpg)\n",
    "----\n",
    "#### Conv2D (фильтр/ядро скользит в двух измерениях)\n",
    "- Conv2D может быть \"разложен\" на два блока Conv1D, объединение вертикального Conv1D и горизонтального Conv1D фиксирует пространственную корреляцию по обеим осям. Это приемлемый подход к классификации изображений в качестве альтернативы Conv2D.\n",
    "![-](data/conv2d_il.gif)\n",
    "----\n",
    "#### Conv3D (фильтр/ядро скользит в трех измерениях)\n",
    "- Conv3D в основном используется с данными трехмерного изображения. Такие какМагнитно-резонансная томография(МРТ) данные. Данные МРТ широко используются для исследования головного мозга, спинного мозга, внутренних органов и многих других.Компьютерная томография(КТ) Сканирование также является примером трехмерных данных, которые создаются путем объединения серии рентгеновских изображений, полученных под разными углами вокруг тела. Мы можем использовать Conv3D для классификации этих медицинских данных или извлечения из них функций.\n",
    "![-](data/conv3d_il.png)\n",
    "----\n",
    "### Вывод:\n",
    "Одной из задач свертки является показать зависимость соседних клеток, которые и формируют картинку. 1D Convolution не подойдет, потому что такой вариант свертки покажет зависимость соседних пикселей только в одной оси. 3D Convolution не уместен для данного датасета, потому что у нас изображения размером (32, 32, 3). 2D Convolution лучше всего подходит для классификации rgb изображений\n",
    "### `В проекте используем только 2D Convolution`\n",
    "----\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolution types\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Convolution\n",
    "[tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/conv2d1.gif)\n",
    "![](data/conv2d2.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Много рассказывать про данный вариант свертки не буду, мы использовали его в семинарах\n",
    "\n",
    "Можно сказать, что такой вариант свертки показал себя хорошо на датасете mnist, который очень отдальенно напоминает svhn.\n",
    "\n",
    "#### `Такой вариант свертки мы будем использовать`\n",
    "\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Convolution\n",
    "[tf.keras.layers.Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/convtranspose.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный вариант свертки увеличивает входные данные с помощью фильтра, размер которого больше входного слоя.\n",
    "\n",
    "В интернете не нашел ни один вариант использования данной свертки без других типов convolution. Как я понял, такая свертка является доплнительным инстурментом.\n",
    "\n",
    "Примером является U-net.\n",
    "\n",
    "### `Использовать будем, но при дальнейшем изучении skip-connection и U-net подобных сетей`\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution LSTM\n",
    "[tf.keras.layers.ConvLSTM2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сетевая структура, способная улавливать пространственно-временные корреляции, а именно ConvLSTM. В Keras это отражено в классе ConvLSTM2D, который вычисляет сверточные операции как во входных данных, так и в рекуррентных преобразованиях.\n",
    "Это больше используется для видео (временная корреляция изображений)\n",
    "#### `Мы это использовать не будем`\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depthwise Convolution\n",
    "[tf.keras.layers.DepthwiseConv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/depthwise_conv.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для svhn данный вариант свертки будет работать так:\n",
    "- Каждый входящий слой (глубина каждого цвета) будет делиться на три отдельных слоя\n",
    "- Для каждого слоя будет создан фильтр размера (n, n, 1)\n",
    "- Каждый входной слой будет \"прогоняться\" через свой фильтр\n",
    "\n",
    "Плюсы:\n",
    "- Уменьшаем кол-во вычеслений (сильно)\n",
    "- Хорошо показываем зависимость соседних пикселей\n",
    "\n",
    "Минусы:\n",
    "- Мы не учитываем зависимость между слоями\n",
    "\n",
    "#### `Проверим на практике работоспособность такого варианта свертки`\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable Convolution\n",
    "[tf.keras.layers.SeparableConv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/separable_conv.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для svhn данный вариант свертки будет работать так:\n",
    "- Каждый входящий слой (глубина каждого цвета) будет делиться на три отдельных слоя\n",
    "- Для каждого слоя будет создан фильтр размера (n, n, 1)\n",
    "- Каждый входной слой будет \"прогоняться\" через свой фильтр\n",
    "- Далее все образоваашиеся слои будут \"прогоняться\" через Pointwise Convolution (точечная свертка)\n",
    "\n",
    "Плюсы:\n",
    "- Уменьшаем кол-во вычеслений (примерно в 9 раз!!!)\n",
    "- Хорошо показываем зависимость соседних пикселей\n",
    "- Мы учитываем зависимость между слоями\n",
    "\n",
    "Минусы:\n",
    "- Не заметил\n",
    "\n",
    "То есть такой вариант свертки также хорош как и Depthwise Conv, однако он исключает его минусы. \n",
    "#### `Проверим на практике работоспособность такого варианта свертки`\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типы сверток, которые мы будем проверять на практике:\n",
    "     - Conv2D\n",
    "     - DepthwiseConv2D\n",
    "     - SeparableConv2D\n",
    "- `Conv2DTranspose` (но не в этом ноуте)\n",
    "----\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling \n",
    "- Подобно сверточному слою, пулинговый слой необходим для уменьшения размера свернутого элемента в пространстве. Это помогает уменьшить вычислительную мощность, необходимую для обработки данных, за счет уменьшения размерности.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии со сверкой, мы отказываемся от 1D Pooling и 3D Pooling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Average Pooling\n",
    "[tf.keras.layers.AveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/avgpool.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отражает средние значения пикселей, из выборки pool_size\n",
    " \n",
    "- Минимальое искажение изображения"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Max Pooling\n",
    "[tf.keras.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/maxpool.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показывает максимальное значения пикселей, из выборки pool_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Показывает выделяющиеся фичи, однако искажает изображение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Global Average Pooling\n",
    "[tf.keras.layers.GlobalAveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/globalavgpool.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показывает средние значения пикселей, из входящего слоя"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Global Max Pooling\n",
    "[tf.keras.layers.GlobalMaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](data/globalmaxpool.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показывает средние значения пикселей, из входящего слоя"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "- Avg vs Max:\n",
    "\n",
    "        Ничего сказать не могу, оба варианта стоит посмотреть на практике\n",
    "\n",
    "- Base vs Global:\n",
    "\n",
    "        Base уже показывал себя хорошо во время семинаров. Global будет работать плохо, потому что после одного такого пулинга, мы теряем колоссальное кол-во данных (остатется всего по 1 значению от каждого слоя)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Типы пулингов, которые мы будем проверять на практике:\n",
    "     - AveragePooling2D\n",
    "     - MaxPool2D\n",
    "----\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комбинации convolutions и polling на практике.\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conv2D + AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conv2D + MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DepthwiseConv2D + AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DepthwiseConv2D + MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SeparableConv2D + AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SeparableConv2D + MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
