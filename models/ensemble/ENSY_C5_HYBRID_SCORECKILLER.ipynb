{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Salam\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
                        "\n",
                        "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
                        "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
                        "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
                        "\n",
                        "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
                        "\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "\n",
                "import seaborn\n",
                "from tensorflow.keras import datasets, layers, models, losses\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "import tensorflow as tf\n",
                "import torchvision as tv\n",
                "import matplotlib.pyplot as plt\n",
                "from livelossplot import PlotLossesKeras\n",
                "import tensorflow_addons as tfa\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import pickle\n",
                "\n",
                "sys.path.append('../../')\n",
                "\n",
                "from core.datasets import get_ds, open_f\n",
                "from core.make_answer import make_ans_file \n",
                "from core.ensembles import get_bagging_pred, print_bagging_ensemble_statistic, print_models_statistic, get_ensemble_modelbase, get_modeset, get_raw_bagging_pred\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Продолжение экспериментов с ансамблями"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "transformer = tv.transforms.Compose([\n",
                "    tv.transforms.ColorJitter(brightness=.2, hue=0.2, contrast=0.5),\n",
                "    tv.transforms.RandomAffine(degrees=(-10, 10), translate=(0, 0.1), scale=(0.85, 1)),\n",
                "    tv.transforms.RandomPerspective(distortion_scale=0.2, p=0.7),\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc_test_ds = open_f(\"smote_data_train_5000\", back=2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc_test_ds_y = acc_test_ds[\"labels\"]\n",
                "acc_test_ds_x = acc_test_ds[\"images\"] / 255."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds, val_ds, test_ds = get_ds('repaired_data_train', 'repaired_data_test', transform=transformer, one_hot=True, back=2)\n",
                "val_ds_x = np.array([i[0] for i in val_ds.unbatch().as_numpy_iterator()])\n",
                "val_ds_y = np.array([i[1] for i in val_ds.unbatch().as_numpy_iterator()])\n",
                "val_ds_y = np.argmax(val_ds_y, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_1 = tf.keras.models.load_model(f'../checkpoints/model_g_1_categorical_accuracy.h5')\n",
                "model_3 = tf.keras.models.load_model(f'../checkpoints/model_g_3_avg_categorical_accuracy.h5')\n",
                "model_smote = tf.keras.models.load_model(f'../checkpoints/model_s_smote_avg_categorical_accuracy.h5')\n",
                "model_c = tf.keras.models.load_model(f'../checkpoints/model_C_EN_1_categorical_accuracy.h5')\n",
                "model_8 = tf.keras.models.load_model(f'../checkpoints/model_g_8_avg_categorical_accuracy.h5')\n",
                "model_16 = tf.keras.models.load_model(f'../checkpoints/model_g_16_avg_categorical_accuracy.h5')\n",
                "model_17 = tf.keras.models.load_model(f'../checkpoints/model_g_17_avg_categorical_accuracy.h5')\n",
                "model_g_11 = tf.keras.models.load_model(f'../checkpoints/model_g_11_avg_f1_score.h5')\n",
                "model_s_6 = tf.keras.models.load_model(f'../checkpoints/model_s_6_avg_f1_score.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "ova_0 = tf.keras.models.load_model(f'../checkpoints/model_zero_avg_categorical_accuracy.h5')\n",
                "ova_1 = tf.keras.models.load_model(f'../checkpoints/model_one_avg_categorical_accuracy.h5')\n",
                "ova_2 = tf.keras.models.load_model(f'../checkpoints/model_two_avg_categorical_accuracy.h5')\n",
                "ova_3 = tf.keras.models.load_model(f'../checkpoints/model_three_avg_categorical_accuracy.h5')\n",
                "ova_4 = tf.keras.models.load_model(f'../checkpoints/model_four_avg_categorical_accuracy.h5')\n",
                "ova_5 = tf.keras.models.load_model(f'../checkpoints/model_five_avg_categorical_accuracy.h5')\n",
                "ova_6 = tf.keras.models.load_model(f'../checkpoints/model_six_avg_categorical_accuracy.h5')\n",
                "ova_7 = tf.keras.models.load_model(f'../checkpoints/model_seven_avg_categorical_accuracy.h5')\n",
                "ova_8 = tf.keras.models.load_model(f'../checkpoints/model_eight_avg_categorical_accuracy.h5')\n",
                "ova_9 = tf.keras.models.load_model(f'../checkpoints/model_nine_avg_categorical_accuracy.h5')\n",
                "\n",
                "ova = {0:ova_0, 1:ova_1, 2:ova_2, 3:ova_3, 4:ova_4, 5:ova_5,  6:ova_6, 7:ova_7, 8:ova_8, 9:ova_9}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {},
            "outputs": [],
            "source": [
                "predict_g11 = pickle.load(open(\"../checkpoint_answers/model_g_11_avg_categorical_accuracy.h5\", 'rb'))\n",
                "predict_s6 = pickle.load(open(\"../checkpoint_answers/model_s_6_avg_categorical_accuracy.h5\", 'rb'))\n",
                "predict_s5 = pickle.load(open(\"../checkpoint_answers/model_s_5_categorical_accuracy.h5\", 'rb'))\n",
                "\n",
                "raw_pred_test = (predict_g11 + predict_s6 + predict_s5) / 3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [],
            "source": [
                "def min_max_scaler(x):\n",
                "    min_x = min(x)\n",
                "    max_x = max(x)\n",
                "    result = []\n",
                "    for i in x:\n",
                "        result.append((i - min_x)/(max_x-min_x))\n",
                "    return np.array(result)\n",
                "\n",
                "# Получить первый/второй/третий по страшинству предикт. (максимальные логиты).\n",
                "def get_ordinal_pred(y_logits, i):\n",
                "    work = list(y_logits.copy())\n",
                "    work.sort(reverse=True)\n",
                "    return list(y_logits).index(work[i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "782/782 [==============================] - 36s 46ms/step\n",
                        "782/782 [==============================] - 36s 46ms/step\n",
                        "782/782 [==============================] - 36s 46ms/step\n",
                        "782/782 [==============================] - 37s 47ms/step\n",
                        "782/782 [==============================] - 37s 46ms/step\n",
                        "782/782 [==============================] - 37s 47ms/step\n",
                        "782/782 [==============================] - 37s 47ms/step\n",
                        "782/782 [==============================] - 36s 46ms/step\n",
                        "782/782 [==============================] - 38s 48ms/step\n",
                        "782/782 [==============================] - 37s 47ms/step\n"
                    ]
                }
            ],
            "source": [
                "ova_test_preds = {}\n",
                "for i in range(10):\n",
                "    ova_test_preds[i] = ova[i].predict(test_ds, verbose=True)\n",
                "\n",
                "final_ova_test_preds = np.full((len(test_ds), 10), 0.)\n",
                "for i in range(len(test_ds)):\n",
                "    l = np.zeros(10)\n",
                "    for j in range(10):\n",
                "        l[j] = ova_test_preds[j][i]\n",
                "    final_ova_test_preds[i] = min_max_scaler(l)\n",
                "\n",
                "final_ova_test_preds_witout_scaler= np.full((len(test_ds), 10), 0.)\n",
                "for i in range(len(test_ds)):\n",
                "    l = np.zeros(10)\n",
                "    for j in range(10):\n",
                "        l[j] = ova_test_preds[j][i]\n",
                "    final_ova_test_preds_witout_scaler[i] = l.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 261,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_activated_ova= np.full((len(test_ds), 10), 0.)\n",
                "for i in range(len(test_ds)):\n",
                "    l = np.zeros(10)\n",
                "    for j in range(10):\n",
                "        l[j] = ova_test_preds[j][i]\n",
                "        if l[j] < 0:\n",
                "            l[j] = 0            \n",
                "    final_activated_ova[i] = l.copy()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Вариант \"Apha Hybrid\": Было выявлено, что так или иначе, когда модель ошибается, правильный ответ стоит у неё на первом или втором по размеру логита месте. Таким образом, если добавить \n",
                "некие дополнительные фильтры, то можно частично исключить эти ошибки. \"Alpa Hybrid\" представляет собой постобработку предиктов ансамбля типа bagging. В качестве фильтров используется 10 моделей \"one vs all\", которые определяют принадлежит ли число указанному классу. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TOTAL: 327 changes, 616 undo\n"
                    ]
                }
            ],
            "source": [
                "# ALPHA HYBRID TEST\n",
                "\n",
                "changes_count = 0\n",
                "undo_count = 0\n",
                "cooked_pred = []\n",
                "for i in range(len(raw_pred_test)):\n",
                "    raw_y = raw_pred_test[i]\n",
                "    first_y_pred = get_ordinal_pred(raw_y, 0)\n",
                "    if ova_test_preds[first_y_pred][i] >= 0:\n",
                "        cooked_pred.append(first_y_pred)\n",
                "        continue\n",
                "    changes_count += 1\n",
                "\n",
                "    second_y_pred = get_ordinal_pred(raw_y, 1)\n",
                "    if ova_test_preds[second_y_pred][i] >= 0:\n",
                "        cooked_pred.append(second_y_pred)\n",
                "        continue\n",
                "\n",
                "    third_y_pred = get_ordinal_pred(raw_y, 2)\n",
                "    if ova_test_preds[third_y_pred][i] >= 0:\n",
                "        cooked_pred.append(third_y_pred)\n",
                "        continue\n",
                "\n",
                "    changes_count-=1\n",
                "    undo_count +=1\n",
                "    cooked_pred.append(first_y_pred)\n",
                "\n",
                "print(f\"TOTAL: {changes_count} changes, {undo_count} undo\")\n",
                "wunderwafel_ensy_alphahybrid = np.array(cooked_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "ensemble_model_name = \"ENSY_C5_APHAHYBRID_wunderwafel\"\n",
                "ans = pd.DataFrame({'Id': np.arange(wunderwafel_ensy_alphahybrid.shape[0]), 'Category': wunderwafel_ensy_alphahybrid})\n",
                "ans.to_csv(f\"../answers/{ensemble_model_name}.csv\", index=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Вариант \"Beta Hybrid\": тут используется иной подход. Берётся 10 логитов с ova-моделей. Предикт каждой ova-модели относительно какого-то числа. Далее к этому массиву применяется MinMaxScaler и этот массив\n",
                "умножается на массив суммы логитов с ансамбля. С полученного результата берётся максимальный логит. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TOTAL: 164 changes, 763 try change, 24073 not changed\n"
                    ]
                }
            ],
            "source": [
                "# BETA HYBRID TEST\n",
                "cooked_pred = []\n",
                "nothing_changed = 0\n",
                "for i in range(len(raw_pred_test)):\n",
                "    if np.argmax(raw_pred_test[i]) == np.argmax(final_ova_test_preds[i]):\n",
                "        cooked_pred.append(np.argmax(raw_pred_test[i]))\n",
                "        nothing_changed+=1\n",
                "        continue\n",
                "    raw_y = raw_pred_test[i]\n",
                "    w = final_ova_test_preds[i] * raw_y\n",
                "    cooked_pred.append(np.argmax(w))\n",
                "\n",
                "\n",
                "changed_count = np.sum(cooked_pred != np.array([np.argmax(k) for k in raw_pred_test]))\n",
                "tried_to_change = len(test_ds) - nothing_changed - changed_count\n",
                "print(f\"TOTAL: {changed_count} changes, {tried_to_change} try change, {nothing_changed} not changed\")\n",
                "wunderwafel_ensy_betahybrid = np.array(cooked_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 276,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "ensemble_model_name = \"1ENSY_C5_BETAHYBRID_wunderwafel\"\n",
                "ans = pd.DataFrame({'Id': np.arange(wunderwafel_ensy_betahybrid.shape[0]), 'Category': wunderwafel_ensy_betahybrid})\n",
                "ans.to_csv(f\"../answers/{ensemble_model_name}.csv\", index=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Вариант \"Gamma Hybrid\": похож на \"Beta Hybrid\", однако не применяется MinMaxScaler к ova-предиктам и вместо умножения прибавление к сумме логитов с ансамбля."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 652,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TOTAL: 321 changes, 606 try change, 24073 not changed\n"
                    ]
                }
            ],
            "source": [
                "# GAMMA HYBRID TEST\n",
                "cooked_pred = []\n",
                "nothing_changed = 0\n",
                "\n",
                "\n",
                "# отладка\n",
                "tried_to_change_l = []\n",
                "\n",
                "\n",
                "for i in range(len(raw_pred_test)):\n",
                "    if np.argmax(raw_pred_test[i]) == np.argmax(final_ova_test_preds_witout_scaler[i]):\n",
                "        cooked_pred.append(np.argmax(raw_pred_test[i]))\n",
                "        nothing_changed+=1\n",
                "        continue\n",
                "    raw_y = raw_pred_test[i]\n",
                "    w = final_ova_test_preds_witout_scaler[i]/3 + raw_y\n",
                "    tried_to_change_l.append(i)\n",
                "    cooked_pred.append(np.argmax(w))\n",
                "\n",
                "\n",
                "changed_count = np.sum(cooked_pred != np.array([np.argmax(k) for k in raw_pred_test]))\n",
                "tried_to_change = len(test_ds) - nothing_changed - changed_count\n",
                "print(f\"TOTAL: {changed_count} changes, {tried_to_change} try change, {nothing_changed} not changed\")\n",
                "wunderwafel_ensy_gammahybrid = np.array(cooked_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 249,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "ensemble_model_name = \"ENSY_C5_GAMMAHYBRID_wunderwafel\"\n",
                "ans = pd.DataFrame({'Id': np.arange(wunderwafel_ensy_gammahybrid.shape[0]), 'Category': wunderwafel_ensy_gammahybrid})\n",
                "ans.to_csv(f\"../answers/{ensemble_model_name}.csv\", index=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Наиболее хорошие результаты показывают Beta и Gamma гибриды"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Серия Hybrid первой смогла пробить accuracy 0.96, однако позже, вышла на потолок своих структурных возможностей. Более поздние ансамбли с новыми, более качественными моделями, показывали результы до обработки гибридами лучше, чем после. Причина заключается в том, что данная серия структур зависима от ova-моделей, а они в отличии от стандартных моделей не переписывались и не улучшались. По итогу, когда разница между моделями из ансамбля и ova-моделями стала слишком большой, ova-модели стали баластом, который тянул accuracy вниз, а не повышал, как раньше. Потенциально, если переписать ova-модели на том же уровне, на котором сейчас написаны последние модели, то потолок 0.97 можно будет пробить без особых проблем, но это слишком затратно по времени, выгоднее вложиться в обычные модели."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Вывод: серия \"Hybrid\" сыграла важную роль в обеспечении преимущества alt+f4, однако устарела и перестала быть эффективной после потолка accuracy 0.963."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
